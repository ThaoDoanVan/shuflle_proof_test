#![allow(non_snake_case)]

use curve25519_dalek::ristretto::{CompressedRistretto, RistrettoPoint};
use curve25519_dalek::scalar::Scalar;
use curve25519_dalek::traits::VartimeMultiscalarMul;
use curve25519_dalek::traits::MultiscalarMul;

use merlin::Transcript;

use super::{ConstraintSystem, LinearCombination, R1CSProof, Variable};

use errors::R1CSError;
use generators::{BulletproofGens, PedersenGens};
use transcript::TranscriptProtocol;
use curve25519_dalek::traits::IsIdentity;




/// An entry point for verifying a R1CS proof.
///
/// The lifecycle of a `Verifier` is as follows. The verifying code
/// provides high-level commitments one by one,
/// `Verifier` adds them to the transcript and returns
/// the corresponding variables.
///
/// After all variables are committed, the verifying code calls `finalize_inputs`,
/// which consumes `Verifier` and returns `VerifierCS`.
/// The verifying code then allocates low-level variables and adds constraints to the `VerifierCS`.
///
/// When all constraints are added, the verifying code calls `verify`
/// on the instance of the constraint system to check the proof.
pub struct Verifier<'a, 'b> {
    /// Number of high-level variables
    m: u64,

    /// Constraint system implementation
    cs: VerifierCS<'a, 'b>,
}

/// A [`ConstraintSystem`] implementation for use by the verifier.
pub struct VerifierCS<'a, 'b> {
    bp_gens: &'b BulletproofGens,
    pc_gens: &'b PedersenGens,
    transcript: &'a mut Transcript,
    constraints: Vec<LinearCombination>,
    /// Records the number of low-level variables allocated in the
    /// constraint system.
    ///
    /// Because the `VerifierCS` only keeps the constraints
    /// themselves, it doesn't record the assignments (they're all
    /// `Missing`), so the `num_vars` isn't kept implicitly in the
    /// variable assignments.
    num_vars: usize,
    V: Vec<CompressedRistretto>,
    num_inputs: usize,
    
}

impl<'a, 'b> ConstraintSystem for VerifierCS<'a, 'b> {
    fn multiply(
        &mut self,
        mut left: LinearCombination,
        mut right: LinearCombination,
    ) -> (Variable, Variable, Variable) {
        let var = self.num_vars;
        self.num_vars += 1;

        // Create variables for l,r,o
        let l_var = Variable::MultiplierLeft(var);
        let r_var = Variable::MultiplierRight(var);
        let o_var = Variable::MultiplierOutput(var);

        // Constrain l,r,o:
        left.terms.push((l_var, -Scalar::one()));
        right.terms.push((r_var, -Scalar::one()));
        self.constrain(left);
        self.constrain(right);

        (l_var, r_var, o_var)
    }

    fn allocate<F>(&mut self, _: F) -> Result<(Variable, Variable, Variable), R1CSError>
    where
        F: FnOnce() -> Result<(Scalar, Scalar, Scalar), R1CSError>,
    {
        let var = self.num_vars;
        self.num_vars += 1;

        // Create variables for l,r,o
        let l_var = Variable::MultiplierLeft(var);
        let r_var = Variable::MultiplierRight(var);
        let o_var = Variable::MultiplierOutput(var);

        Ok((l_var, r_var, o_var))
    }

    fn constrain(&mut self, lc: LinearCombination) {
        // TODO: check that the linear combinations are valid
        // (e.g. that variables are valid, that the linear combination
        // evals to 0 for prover, etc).
        self.constraints.push(lc);
    }

    fn challenge_scalar(&mut self, label: &'static [u8]) -> Scalar {
        self.transcript.challenge_scalar(label)
    }
}

impl<'a, 'b> Verifier<'a, 'b> {
    /// Construct an empty constraint system with specified external
    /// input variables.
    ///
    /// # Inputs
    ///
    /// The `bp_gens` and `pc_gens` are generators for Bulletproofs
    /// and for the Pedersen commitments, respectively.  The
    /// [`BulletproofGens`] should have `gens_capacity` greater than
    /// the number of multiplication constraints that will eventually
    /// be added into the constraint system.
    ///
    /// The `transcript` parameter is a Merlin proof transcript.  The
    /// `VerifierCS` holds onto the `&mut Transcript` until it consumes
    /// itself during [`VerifierCS::verify`], releasing its borrow of the
    /// transcript.  This ensures that the transcript cannot be
    /// altered except by the `VerifierCS` before proving is complete.
    ///
    /// The `commitments` parameter is a list of Pedersen commitments
    /// to the external variables for the constraint system.  All
    /// external variables must be passed up-front, so that challenges
    /// produced by [`ConstraintSystem::challenge_scalar`] are bound
    /// to the external variables.
    ///
    /// # Returns
    ///
    /// Returns a tuple `(cs, vars)`.
    ///
    /// The first element is the newly constructed constraint system.
    ///
    /// The second element is a list of [`Variable`]s corresponding to
    /// the external inputs, which can be used to form constraints.
    pub fn new(
        bp_gens: &'b BulletproofGens,
        pc_gens: &'b PedersenGens,
        transcript: &'a mut Transcript,
    ) -> Self {
        transcript.r1cs_domain_sep();

        Verifier {
            m: 0,
            cs: VerifierCS {
                bp_gens,
                pc_gens,
                transcript,
                num_vars: 0,
                V: Vec::new(),
                constraints: Vec::new(),
                num_inputs:0, // number of inputs + shuffled outputs
                
            },
        }
    }

    /// Creates commitment to a high-level variable and adds it to the transcript.
    ///
    /// # Inputs
    ///
    /// The `commitment` parameter is a Pedersen commitment
    /// to the external variable for the constraint system.  All
    /// external variables must be passed up-front, so that challenges
    /// produced by [`ConstraintSystem::challenge_scalar`] are bound
    /// to the external variables.
    ///
    /// # Returns
    ///
    /// Returns a pair of a Pedersen commitment (as a compressed Ristretto point),
    /// and a [`Variable`] corresponding to it, which can be used to form constraints.
    pub fn commit(&mut self, commitment: CompressedRistretto) -> Variable {
        let i = self.m as usize;
        self.m += 1;
        self.cs.V.push(commitment);

        // Add the commitment to the transcript.
        self.cs.transcript.commit_point(b"V", &commitment);

        Variable::Committed(i)
    }

    ///
    pub fn commit_vec(
        &mut self,
        commitment: CompressedRistretto,
        n: usize,
    ) -> Vec<Variable> {
        let start_index = self.m as usize;

        // Increase the commitment counter
        self.m += n as u64;
        self.cs.num_inputs = self.m as usize;

        self.cs.V.push(commitment);
        self.cs.transcript.commit_point(b"V", &commitment);

        // Return n committed variables corresponding to the vector entries
        (start_index..start_index + n)
            .map(|i| Variable::Committed(i))
            .collect()
    }

    /// Consume the `Verifier`, provide the `ConstraintSystem` implementation to the closure,
    /// and verify the proof against the resulting constraint system.
    pub fn finalize_inputs(self) -> VerifierCS<'a, 'b> {
        // Commit a length _suffix_ for the number of high-level variables.
        // We cannot do this in advance because user can commit variables one-by-one,
        // but this suffix provides safe disambiguation because each variable
        // is prefixed with a separate label.
        self.cs.transcript.commit_u64(b"m", self.m);
        self.cs
    }
}

/// Finds the smallest power of k (i.e., k^x)
/// that is greater than or equal to n, using a
/// fast logarithm-based estimation with integer correction.
///
#[inline] // Hint to the compiler to inline this small, hot function
fn next_power_of_k(n: usize, k: usize) -> usize {
    // --- 1. Handle edge cases ---
    
    // k^0 = 1. This is the smallest power.
    if n <= 1 {
        return 1;
    }

    match k {
        0 => panic!("Cannot find a power of 0 >= {}", n),
        1 => panic!("Cannot find a power of 1 >= {}", n), // 1^x is always 1
        
        // --- 2. Main logic for k >= 2 ---
        _ => {
            // --- 3. Estimate exponent using floating-point logs ---
            // We want to find the smallest integer 'x' such that k^x >= n.
            // This is equivalent to x >= log_k(n).
            // So, we calculate x = ceil(log_k(n)).
            // We use log_k(n) = ln(n) / ln(k).
            
            let n_f = n as f64;
            let k_f = k as f64;
            let exponent = (n_f.ln() / k_f.ln()).ceil() as u32;

            // --- 4. Calculate the estimated power ---
            // This is our first guess, k^x.
            let mut power = k.checked_pow(exponent)
                .unwrap_or_else(|| panic!("Overflow: k^x exceeds usize::MAX"));

            // --- 5. Correct for floating-point inaccuracies ---

            // Case A: Guess was too low (due to precision errors, n_f.ln() / k_f.ln()
            // was slightly less than an integer, and ceil() rounded to x-1).
            // If power < n, we need the next power up.
            if power < n {
                power = power.checked_mul(k)
                    .unwrap_or_else(|| panic!("Overflow: k^x * k exceeds usize::MAX"));
            }
            
            // Case B: Guess was too high (due to precision errors, ceil()
            // rounded up unnecessarily).
            // We check if the *previous* power, k^(x-1), was already >= n.
            if let Some(prev_power) = power.checked_div(k) {
                if prev_power >= n {
                    power = prev_power;
                }
            }
            
            power
        }
    }
}



impl<'a, 'b> VerifierCS<'a, 'b> {
    /// Use a challenge, `z`, to flatten the constraints in the
    /// constraint system into vectors used for proving and
    /// verification.
    ///
    /// # Output
    ///
    /// Returns a tuple of
    /// ```text
    /// (wL, wR, wO, wV, wc)
    /// ```
    /// where `w{L,R,O}` is \\( z \cdot z^Q \cdot W_{L,R,O} \\).
    ///
    /// This has the same logic as `ProverCS::flattened_constraints()`
    /// but also computes the constant terms (which the prover skips
    /// because they're not needed to construct the proof).
    fn flattened_constraints(
        &mut self,
        z: &Scalar,
    ) -> (Vec<Scalar>, Vec<Scalar>, Vec<Scalar>, Vec<Scalar>, Scalar) {
        let n = self.num_vars; //both from x and y sides
        let m = self.num_inputs; // = self.V.len();

        let mut wL = vec![Scalar::zero(); n];
        let mut wR = vec![Scalar::zero(); n];
        let mut wO = vec![Scalar::zero(); n];
        let mut wV = vec![Scalar::zero(); m];
        let mut wc = Scalar::zero();

        let mut exp_z = *z;
        for lc in self.constraints.iter() {
            for (var, coeff) in &lc.terms {
                match var {
                    Variable::MultiplierLeft(i) => {
                        wL[*i] += exp_z * coeff;
                    }
                    Variable::MultiplierRight(i) => {
                        wR[*i] += exp_z * coeff;
                    }
                    Variable::MultiplierOutput(i) => {
                        wO[*i] += exp_z * coeff;
                    }
                    Variable::Committed(i) => {
                        wV[*i] -= exp_z * coeff;
                    }
                    Variable::One() => {
                        wc -= exp_z * coeff;
                    }
                }
            }
            exp_z *= z;
        }

        (wL, wR, wO, wV, wc)
    }

  pub fn verify(
    mut self,
    proof: &R1CSProof,
    C1_prime: &[RistrettoPoint],
    C2_prime: &[RistrettoPoint],
    C: &[RistrettoPoint],
) -> Result<(), R1CSError> {
    // Standard Imports
    use curve25519_dalek::traits::IsIdentity;
    use inner_product_proof::inner_product;
    use rand::thread_rng;
    use std::iter;
    use util;

    // -----------------------------------------------------------------------------
    // 1. Checks & Padding (PARTIAL FOLDING)
    // -----------------------------------------------------------------------------
    let n = self.num_vars;
    let padded_n = self.num_inputs;
    let k_fold = proof.ipp_proof.k;

    /*// --- Derive padded_n from the Proof Structure ---
    // Since the optimization  of LinearCombination * (-z)) n = self.num_vars # Prover's
    // Compute padded_n = m * k^d from the proof
    let k_fold = proof.ipp_proof.k;
    let num_rounds = proof.ipp_proof.U_vecs.len(); // Depth d
    let m = proof.ipp_proof.a_final.len();
   
    //let m = self.num_inputs;

    // Calculate N = m * k^d
    // This is the size the Prover committed to.
    let mut padded_n = m;
    for _ in 0..num_rounds {
        padded_n = padded_n.checked_mul(k_fold)
            .ok_or(R1CSError::VerificationError)?;
    }
    
    // Ensure the proof is large enough for our real constraints
    if padded_n < n { 
        return Err(R1CSError::VerificationError); 
    }
    */

    let pad = padded_n - n;


    if self.bp_gens.gens_capacity < padded_n {
        return Err(R1CSError::InvalidGeneratorsLength);
    }

    // We are performing a single-party circuit proof, so party index is 0.
    let gens = self.bp_gens.share(0);

    // -----------------------------------------------------------------------------
    // 2. Transcript Interaction
    // -----------------------------------------------------------------------------
    // Commit Circuit Points
    self.transcript.commit_point(b"A_I", &proof.A_I);
    self.transcript.commit_point(b"A_O", &proof.A_O);
    self.transcript.commit_point(b"S", &proof.S);

    // Get Challenges y, z
    let y = self.transcript.challenge_scalar(b"y");
    let z = self.transcript.challenge_scalar(b"z");

    // Commit T Points
    self.transcript.commit_point(b"T_1", &proof.T_1);
    self.transcript.commit_point(b"T_3", &proof.T_3);
    self.transcript.commit_point(b"T_4", &proof.T_4);
    self.transcript.commit_point(b"T_5", &proof.T_5);
    self.transcript.commit_point(b"T_6", &proof.T_6);
    self.transcript.commit_point(b"T_2", &proof.T_2);

    let x = self.transcript.challenge_scalar(b"x");

    // Commit Scalars
    self.transcript.commit_scalar(b"t_x", &proof.t_x);
    self.transcript.commit_scalar(b"t_x_blinding", &proof.t_x_blinding);
    self.transcript.commit_scalar(b"e_blinding", &proof.e_blinding);

    let (wL, wR, wO, wV, wc) = self.flattened_constraints(&z);

    // External Consistency Setup (Megacheck I Setup)
    self.transcript.commit_point(b"S_prime", &proof.S_prime);
    self.transcript.commit_point(b"T_1_prime", &proof.T_1_prime);
    self.transcript.commit_point(b"S1_prime", &proof.S1_prime);
    self.transcript.commit_point(b"S2_prime", &proof.S2_prime);

    let x_prime = self.transcript.challenge_scalar(b"x_prime");

    self.transcript.commit_scalar(b"tc_x", &proof.tc_x);
    self.transcript.commit_scalar(b"tc_x_blinding", &proof.tc_x_blinding);
    self.transcript.commit_scalar(b"ec_blinding", &proof.ec_blinding);
    self.transcript.commit_scalar(b"r_blinding", &proof.r_blinding);

    // Protocol A: Aggregation Setup
    self.transcript.commit_scalar(b"t_cross", &proof.t_cross);
    let t_cross = proof.t_cross;

    let x_ipp = self.transcript.challenge_scalar(b"x_ipp");
    let w_agg = self.transcript.challenge_scalar(b"w_agg");

    // -----------------------------------------------------------------------------
    // 3. Scalar & Point Reconstruction (PARTIAL FOLDING)
    // -----------------------------------------------------------------------------
    // Get Verification Scalars from the Single Aggregated IPA
    let (s_g_cir, s_h_cir, s_Q_cir, s_P_cir, s_U_cir) = proof
        .ipp_proof
        .verification_scalars(padded_n, self.transcript)
        .map_err(|_| R1CSError::VerificationError)?;


    // Decompress U points safely
    let mut U_points_decompressed_cir: Vec<RistrettoPoint> =
        Vec::with_capacity(proof.ipp_proof.U_vecs.len() * (2 * k_fold - 2));

    for r in 0..proof.ipp_proof.U_vecs.len() {
        for i_list in 0..(2 * k_fold - 2) {
            let U_ir_point_cir = proof.ipp_proof.U_vecs[r][i_list]
                .decompress()
                .ok_or(R1CSError::VerificationError)?;
            U_points_decompressed_cir.push(U_ir_point_cir);
        }
    }

    // Reconstruct Vector Weights
    let y_inv = y.invert();
    let y_inv_vec: Vec<Scalar> = util::exp_iter(y_inv).take(padded_n).collect();

    let yneg_wR: Vec<Scalar> = wR
        .into_iter()
        .zip(y_inv_vec.iter())
        .map(|(wRi, exp_y_inv)| wRi * exp_y_inv)
        .chain(iter::repeat(Scalar::zero()).take(pad))
        .collect();

    let delta = inner_product(&yneg_wR[0..n], &wL);

    // Calculate g_scalars
    let g_scalars: Vec<Scalar> = s_g_cir
        .iter()
        .zip(yneg_wR.iter())
        .map(|(s_g_i, yneg_wR_i)| s_g_i - x * yneg_wR_i * s_P_cir) 
        //.map(|(s_g_i, yneg_wR_i)| s_g_i * a_final - x * yneg_wR_i * s_P_cir)
        .collect();


    let rC: Vec<Scalar> = wV.to_vec();

    // Calculate h_scalars
    let h_scalars: Vec<Scalar> = s_h_cir
        .iter()
        .zip(y_inv_vec.iter())
        .zip(wL.into_iter().chain(iter::repeat(Scalar::zero()).take(pad)))
        .zip(wO.into_iter().chain(iter::repeat(Scalar::zero()).take(pad)))
        .zip(rC.iter())
        .map(|((((s_h_i, y_inv_i), wLi), wOi), rCi)| {
            //let term1 = y_inv_i * s_h_i * b_final;
            let term1 = y_inv_i * s_h_i;
            let term2 = (y_inv_i * (x * wLi + wOi) - Scalar::one()) * (-s_P_cir);
            let term3 = y_inv_i * x_ipp * (-s_P_cir) * rCi;
            term1 + term2 + term3
        })
        .collect();

    // -----------------------------------------------------------------------------
    // 4. Verification Check Setup
    // -----------------------------------------------------------------------------
    let mut rng = self.transcript.build_rng().finalize(&mut thread_rng());
    let r = Scalar::random(&mut rng);

    let xx = x * x;
    let rxx = r * xx;
    let xxx = x * xx;
    let r2 = r * r;

    // T polynomials scalars and points
    let T_scalars = [
        r * x,
        r * xx,
        rxx * x,
        rxx * xx,
        rxx * xxx,
        rxx * xx * xx,
    ];
    let T_points = [
        proof.T_1, proof.T_2, proof.T_3, proof.T_4, proof.T_5, proof.T_6,
    ];

    // Aggregated Inner Product Expectation
    let expected_ip = proof.t_x + x_ipp * t_cross + x_ipp * x_ipp * proof.tc_x;

    // Basepoint Scalar B
    let B_scalar = w_agg * s_Q_cir - w_agg * expected_ip * s_P_cir
        + r * (xx * (wc + delta) - proof.t_x)
        - r2 * proof.tc_x;

    // Blinding Scalar B_blinding
    let B_blinding_scalar = x_ipp * proof.ec_blinding * s_P_cir + proof.e_blinding * s_P_cir
        - r2 * proof.tc_x_blinding
        - r * proof.t_x_blinding;

    // Megacheck III Setup (Batched ECP)
    let chall_batched_ecp = self.transcript.challenge_scalar(b"chall_batched_ecp");

    let r3 = r2 * r;
    let r4 = r3 * r;

    let (z_s_vec, s_P, s_A_vec) = proof
        .ecp_batched
        .verification_scalars(padded_n, self.transcript)
        .map_err(|_| R1CSError::VerificationError)?;

    // Scalars 
    let s_V_checkS = r4 * (-s_P);
    let s_S_prime_checkS = r4 * x_prime * (-s_P);
    let s_S1_prime = r3 * x_prime * (-s_P);
    let s_S2_prime = r3 * chall_batched_ecp * x_prime * (-s_P);
    let s_B_checkS = s_P * r3 * proof.r_blinding;
    let s_C0 = r3 * (-s_P);
    let s_C1 = r3 * chall_batched_ecp * (-s_P);
    let s_B_blinding_checkS =
        s_P * (r4 * proof.ec_blinding + r3 * chall_batched_ecp * proof.r_blinding);

    // Combine scalars for Shared Points
    let final_scalar_V = (-x_ipp * s_P_cir) + s_V_checkS;
    let final_scalar_S_prime = (-x_ipp * s_P_cir * x_prime) + s_S_prime_checkS;
    let final_scalar_B = B_scalar + s_B_checkS;
    let final_scalar_B_blinding = B_blinding_scalar + s_B_blinding_checkS;

    let final_g_scalars: Vec<Scalar> = g_scalars
        .iter()
        .zip(z_s_vec.iter())
        .map(|(g_i, z_i)| g_i + (z_i * r4))
        .collect();

    // -----------------------------------------------------------------------------
    // 5. Final MSM Construction
    // -----------------------------------------------------------------------------
    let k_original = C1_prime.len();

    let combined_scalars: Vec<Scalar> = iter::once(-x * s_P_cir) // A_I
        .chain(iter::once(-x * x * s_P_cir)) // A_O
        .chain(iter::once(-x * x * x * s_P_cir)) // S
        .chain(iter::once(final_scalar_V)) // V[0] (SHARED)
        .chain(iter::once(final_scalar_S_prime)) // S_prime (SHARED)
        .chain(iter::once(final_scalar_B)) // B (SHARED)
        .chain(iter::once(final_scalar_B_blinding)) // B_blinding (SHARED)
        .chain(final_g_scalars.into_iter()) // G vec (SHARED)
        .chain(h_scalars.into_iter()) // H vec (Unique IPA)
        .chain(s_U_cir.iter().map(|s| -s)) // U vec (Unique IPA)
        .chain(iter::once(r2 * x_prime)) // T1_prime (Unique IPA)
        .chain(iter::once(r2)) // T2 (Unique IPA)
        .chain(T_scalars.iter().cloned()) // T points (Unique IPA)
        .chain(iter::once(s_S1_prime)) // S1_prime
        .chain(iter::once(s_S2_prime)) // S2_prime
        .chain(iter::once(s_C0)) // C[0]
        .chain(iter::once(s_C1)) // C[1]
        //.chain(z_s_vec.iter().map(|z| z * r3)) // C1' vec
        //.chain(z_s_vec.iter().map(|z| z * r3 * chall_batched_ecp)) // C2' vec
        .chain(z_s_vec[0..k_original].iter().map(|z| z * r3)) // C1' vec only length k_original
        .chain(z_s_vec[0..k_original].iter().map(|z| z * r3 * chall_batched_ecp)) // C2' vec only length k_original
        .chain(s_A_vec.iter().map(|s_A| -s_A * r4)) // A0 vec
        .chain(s_A_vec.iter().map(|s_A| -s_A * r3)) // A1 vec
        .collect();

    // We collect points safely, returning error if decompression fails
    let combined_points_iter = iter::once(proof.A_I.decompress())
        .chain(iter::once(proof.A_O.decompress()))
        .chain(iter::once(proof.S.decompress()))
        .chain(iter::once(self.V.first().and_then(|v| v.decompress()))) // V[0]
        .chain(iter::once(proof.S_prime.decompress())) // S_prime
        .chain(iter::once(Some(self.pc_gens.B))) // B
        .chain(iter::once(Some(self.pc_gens.B_blinding))) // B_blinding
        .chain(gens.G(padded_n).cloned().map(Some)) // G vec
        .chain(gens.H(padded_n).cloned().map(Some)) // H vec
        .chain(U_points_decompressed_cir.into_iter().map(Some)) // U vec
        .chain(iter::once(proof.T_1_prime.decompress())) // T1_prime
        .chain(iter::once(proof.T_2.decompress())) // T2
        .chain(T_points.iter().map(|T| T.decompress())) // T points
        .chain(iter::once(proof.S1_prime.decompress())) // S1_prime
        .chain(iter::once(proof.S2_prime.decompress())) // S2_prime
        .chain(iter::once(Some(C[0]))) // C[0]
        .chain(iter::once(Some(C[1]))) // C[1]
        .chain(C1_prime.iter().map(|c| Some(*c))) // C1'
        .chain(C2_prime.iter().map(|c| Some(*c))) // C2'
        .chain(
            proof
                .ecp_batched
                .A_vecs
                .iter()
                .flatten()
                .map(|A| A[0].decompress()),
        ) // A0 vec
        .chain(
            proof
                .ecp_batched
                .A_vecs
                .iter()
                .flatten()
                .map(|A| A[1].decompress()),
        ); // A1 vec

    // Collect into Vec<RistrettoPoint>, checking for decompression errors
    let combined_points: Vec<RistrettoPoint> = combined_points_iter
        .collect::<Option<Vec<_>>>()
        .ok_or(R1CSError::VerificationError)?;

    // -----------------------------------------------------------------------------
    // 6. Final Execution
    // -----------------------------------------------------------------------------
    let mega_check = RistrettoPoint::vartime_multiscalar_mul(combined_scalars, combined_points);

    if !mega_check.is_identity() {
        return Err(R1CSError::VerificationError);
    }

    Ok(())
}
  
       }
        